{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import streamlit as st\n",
    "import openai\n",
    "import uuid\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch country metadata\n",
    "url = \"http://api.worldbank.org/v2/country?format=json&per_page=300\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    metadata = response.json()\n",
    "    countries = metadata[1]\n",
    "    individual_countries = [c['id'] for c in countries if c['region']['value'] != \"Aggregates\"]\n",
    "else:\n",
    "    print(\"Failed to fetch country metadata\")\n",
    "    individual_countries = []\n",
    "\n",
    "# Initialize variables\n",
    "all_data = []\n",
    "page = 1\n",
    "MAX_PAGES = 50  # Maximum number of pages to fetch\n",
    "\n",
    "# Fetch GDP data for individual countries only\n",
    "for country in individual_countries:\n",
    "    print(f\"Fetching data for {country}...\")\n",
    "    page = 1\n",
    "    while page <= MAX_PAGES:\n",
    "        url = f\"http://api.worldbank.org/v2/country/{country}/indicator/NY.GDP.MKTP.CD?format=json&page={page}\"\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve data for {country} on page {page}\")\n",
    "            break\n",
    "        \n",
    "        data = response.json()\n",
    "        if len(data) < 2 or not data[1]:\n",
    "            break  # Exit if there is no more data\n",
    "\n",
    "        # Extract records\n",
    "        records = data[1]\n",
    "        for record in records:\n",
    "            if record['value'] is not None:  # Skip null values\n",
    "                country_name = record['country']['value']\n",
    "                year = record['date']\n",
    "                gdp = record['value']\n",
    "                all_data.append([country_name, year, gdp])\n",
    "        \n",
    "        page += 1  # Move to the next page\n",
    "        time.sleep(1)  # Avoid rate-limiting\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_data, columns=['Country', 'Year', 'GDP'])\n",
    "\n",
    "# Clean the data\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df['GDP'] = pd.to_numeric(df['GDP'], errors='coerce')\n",
    "df = df[df['Year'] >= 2000]  # Filter data from the year 2000 onwards\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('world_bank_gdp_cleaned.csv', index=False)\n",
    "print(\"Data successfully saved to 'world_bank_gdp_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "df = pd.read_csv('world_bank_gdp_cleaned.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "summaries = []\n",
    "for _, row in df.iterrows():\n",
    "    summaries.append(f\"In {row['Year']}, {row['Country']} had a GDP of ${row['GDP']:,.0f}.\")\n",
    "    \n",
    "# Example output\n",
    "print(summaries[:5])\n",
    "\n",
    "\n",
    "table_text = \"\"\n",
    "for _, row in df.iterrows():\n",
    "    table_text += f\"Country: {row['Country']}, Year: {row['Year']}, GDP: ${row['GDP']:,.0f}\\n\"\n",
    "\n",
    "# Example output\n",
    "print(table_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your valid OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your key\n",
    "\n",
    "# Load the preprocessed prompt\n",
    "with open('gdp_table.txt', 'r') as f:\n",
    "    prompt = f.read()\n",
    "\n",
    "# Reduce input length\n",
    "prompt = prompt[-12000:]  # Adjust size to fit within token limits\n",
    "\n",
    "# Define a question\n",
    "question = \"Which country had the highest GDP in 2020?\"\n",
    "\n",
    "# Make a GPT-3.5-turbo or GPT-4 API call\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant trained to analyze economic data.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},  # Load the data as context\n",
    "        {\"role\": \"user\", \"content\": question}  # Add your question\n",
    "    ],\n",
    "    max_tokens=500,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Output the response\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically start Streamlit if the script is run directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the script is already running in Streamlit\n",
    "    if not os.getenv(\"IS_RUNNING_STREAMLIT\"):\n",
    "        # Set an environment variable to avoid recursion\n",
    "        os.environ[\"IS_RUNNING_STREAMLIT\"] = \"1\"\n",
    "        \n",
    "        # Launch Streamlit\n",
    "        streamlit_command = f\"streamlit run {os.path.abspath(__file__)}\"\n",
    "        print(f\"Launching Streamlit app: {streamlit_command}\")\n",
    "        subprocess.run(streamlit_command, shell=True)\n",
    "        sys.exit()\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your API key\n",
    "\n",
    "# Initialize session state variables\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state['messages'] = []\n",
    "if 'chat_id' not in st.session_state:\n",
    "    st.session_state['chat_id'] = str(uuid.uuid4())\n",
    "if 'data_context' not in st.session_state:\n",
    "    st.session_state['data_context'] = \"\"\n",
    "\n",
    "# Load predefined data only once\n",
    "if not st.session_state['data_context']:\n",
    "    file_path = \"/Users/riis57/gdp_summaries.txt\"  # Replace with your file path\n",
    "    try:\n",
    "        # Read the text file (but do NOT display it)\n",
    "        with open(file_path, 'r') as file:\n",
    "            st.session_state['data_context'] = file.read()\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"The file at {file_path} could not be found. Please check the file path.\")\n",
    "        st.stop()\n",
    "\n",
    "# Streamlit app title\n",
    "st.title(\"GDP Data Analysis with GPT\")\n",
    "\n",
    "# Display the conversation using st.chat_message\n",
    "for message in st.session_state['messages']:\n",
    "    if message['role'] == 'user':\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.write(message['content'])\n",
    "    else:\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.write(message['content'])\n",
    "\n",
    "# Accept user input using st.chat_input\n",
    "user_input = st.chat_input(\"Ask your question about the data:\")\n",
    "\n",
    "if user_input:\n",
    "    # Append the user's message to the session state\n",
    "    st.session_state['messages'].append({'role': 'user', 'content': user_input})\n",
    "\n",
    "    # Display the user's message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_input)\n",
    "\n",
    "    # Trim the data context if it exceeds token limits\n",
    "    data_context = st.session_state['data_context']\n",
    "    if len(data_context) > 12000:  # Adjust the limit as needed\n",
    "        data_context = data_context[:12000]\n",
    "\n",
    "    # Send the question to GPT\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant trained to analyze economic data.\"},\n",
    "                {\"role\": \"user\", \"content\": data_context},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # Extract GPT's response\n",
    "        bot_reply = response['choices'][0]['message']['content']\n",
    "\n",
    "        # Append the bot's reply to the session state\n",
    "        st.session_state['messages'].append({'role': 'assistant', 'content': bot_reply})\n",
    "\n",
    "        # Display GPT's response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.write(bot_reply)\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
